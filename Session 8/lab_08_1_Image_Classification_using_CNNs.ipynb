{"cells":[{"cell_type":"markdown","metadata":{"id":"r4rCKcndPybL"},"source":["# Laboratory #4_1 : Image Classification using CNN\n","\n","At the end of this laboratory, you would get familiarized with\n","\n","*   Creating deep networks using Keras\n","*   Steps necessary in training a neural network\n","*   Prediction and performance analysis using neural networks\n","*   Using pre-trained networks\n","*   Feature visualizations\n","\n","**Remember this is a graded exercise.**\n","\n","*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n","*   Create reusable functions where ever possible, so that the code could be reused at different places.\n","*   Mount your drive to access the images.\n","*   Add sufficient comments and explanations wherever necessary.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"KdglSzOi4Cp-"},"source":["# **Colaboratory environment**\n","By default, Colab notebooks run on CPU.\n","You can switch your notebook to run with GPU.\n","\n","In order to obtain access to the GPU, you need to choose the tab Runtime and then select “Change runtime type” as shown in the following figure:\n","\n","![Changing runtime](https://miro.medium.com/max/747/1*euE7nGZ0uJQcgvkpgvkoQg.png)\n","\n","When a pop-up window appears select GPU. Ensure “Hardware accelerator” is set to GPU."]},{"cell_type":"markdown","metadata":{"id":"9wkicuxZdrdq"},"source":["# **Working with a new dataset: CIFAR-10**\n","\n","The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. More information about CIFAR-10 can be found [here](https://www.cs.toronto.edu/~kriz/cifar.html).\n","\n","In Keras, the CIFAR-10 dataset is also preloaded in the form of four Numpy arrays. x_train and y_train contain the training set, while x_test and y_test contain the test data. The images are encoded as Numpy arrays and their corresponding labels ranging from 0 to 9.\n","\n","Your task is to:\n","\n","*   Visualize the images in CIFAR-10 dataset. Create a 10 x 10 plot showing 10 random samples from each class.\n","*   Convert the labels to one-hot encoded form.\n","*   Normalize the images.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mrb20KGMtTFq"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2ER5WlMNRydp"},"source":["## Define the following model (same as the one in tutorial)\n","\n","**For the convolutional front-end, start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer. Use the input as (32,32,3). The filter maps can then be flattened to provide features to the classifier. Use a dense layer with 100 units before the classification layer (which is also a dense layer with softmax activation).**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WfWCHxh8HGhN"},"outputs":[],"source":["from keras.backend import clear_session\n","clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iSN6riPISBMG"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PGtivbQJT39U"},"source":["*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n","*   Use the above defined model to train CIFAR-10 and train the model for 512 epochs with a batch size of 32."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hn8UzPBZugVp"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"G2mrWK5hSB_o"},"source":["## Defining Deeper Architectures: VGG Models\n","\n","*   Define a deeper model architecture for CIFAR-10 dataset and train the new model for 512 epochs with a batch size of 32. We will use VGG model as the architecture.\n","\n","**Stack two convolutional layers with 32 filters, each of 3 x 3. Use a max pooling layer and next flatten the output of the previous layer and add a dense layer with 128 units before the classification layer. For all the layers, use ReLU activation function. Use same padding for the layers to ensure that the height and width of each layer output matches the input**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A80vLxW9FIek"},"outputs":[],"source":["from keras.backend import clear_session\n","clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgca5dUNSFNc"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZwaPphEBUtlC"},"source":["*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n","*   Use the above defined model to train CIFAR-10 and train the model for 512 epochs with a batch size of 32."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bc2qtU0mUvVA"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_2cRr2ZFSFds"},"source":["*   Compare the performance of both the models by plotting the loss and accuracy curves of both the training steps. Does the deeper model perform better? Comment on the observation.\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8OSHAf5SJPr"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ri9kU3wa3Rei"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"MzXmO1WoSKMY"},"source":["*   Use predict function to predict the output for the test split\n","*   Plot the confusion matrix for the new model and comment on the class confusions.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DObaoxhaSMUg"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WUBrvRomU5O_"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"ffwVz-FLSNG7"},"source":["*    Print the test accuracy for the trained model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L4WX3_uLSN5I"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dySqfA6PVBjQ"},"source":["## Define the complete VGG architecture.\n","\n","**Stack two convolutional layers with 64 filters, each of 3 x 3 followed by max pooling layer. Stack two more convolutional layers with 128 filters, each of 3 x 3, followed by max pooling, follwed by two more convolutional layers with 256 filters, each of 3 x 3, followed by max pooling. Flatten the output of the previous layer and add a dense layer with 128 units before the classification layer. For all the layers, use ReLU activation function. Use same padding for the layers to ensure that the height and width of each layer output matches the input**\n","\n","*   Change the size of input to 64 x 64."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zm35siILFNT0"},"outputs":[],"source":["from keras.backend import clear_session\n","clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oH4lDVBuVA_Q"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Qu_B8kJGWhcM"},"source":["*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n","*   Use the above defined model to train CIFAR-10 and train the model for 100 epochs with a batch size of 32.\n","*   Predict the output for the test split and plot the confusion matrix for the new model and comment on the class confusions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4elnDWnjEbmO"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2dlzFt0SXGDQ"},"source":["# Understanding deep networks\n","\n","*   What is the use of activation functions in network? Why is it needed?\n","*   We have used softmax activation function in the exercise. There are other activation functions available too. What is the difference between sigmoid activation and softmax activation?\n","*   What is the difference between categorical crossentropy and binary crossentropy loss?"]},{"cell_type":"markdown","metadata":{"id":"sPy_1EWXX6fp"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"x7JtHCmIxSmn"},"source":["# Transfer Learning\n","\n","It is not always necessary to train models from scratch. We can use the knowledge of networks trained on other tasks to learn the task at hand. In this exercise, we will explore the use of pre-trained weights and train on the CIFAR-10 dataset.\n","\n","*   Create a base imagenet pretrained InceptionV3 model.\n","    *    Hint: Use tf.keras.applications to create the model\n","    *    Pay attention to the include_top parameter.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PvJ-OYIt6FRp"},"outputs":[],"source":["from keras.backend import clear_session\n","clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZPNmumpxJMo"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Sq8urTnlx_ug"},"source":["*    Add a global average pooling layer, followed by a fully-connected layer with 1024 neurons and then the classification layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTR4yCT-yPJk"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"h_rjXkO-yPfN"},"source":["*   Train the model by freezing the base model. Train only the newly added layers.\n","    *    Hint: Every layer has an attribute called 'trainable'\n","*   Compile the model and train the model for a few epochs only."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Szbku96ypDQ"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mlQ5-83TypWy"},"source":["*    Freeze the bottom layers and unfreeze the base layers.\n","*    Compile and train the classifier with a very low learning rate (0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8p-0Jyi6zDWG"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6C8rryZozCr6"},"source":["*    Compare the performance of the VGG model and the Inception-V3 model."]},{"cell_type":"markdown","metadata":{"id":"yzhxMkt82ddr"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"gEA8k0BtzLyI"},"source":["*    When do we train models from scratch? What are the potential issues in training models from scratch?"]},{"cell_type":"markdown","metadata":{"id":"d0ECBMya2e1g"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"arkQv6N_66n2"},"source":["*    Why do we use pre-trained weights?\n","*    What is the difference between using random initialization and using weights from a pre-trained model?"]},{"cell_type":"markdown","metadata":{"id":"oG2sGnxd64Sv"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"K-8E3dBw8Zoa"},"source":["# Extracting features from Deep Networks\n","\n","It is quite possible to extract features (similar to SIFT or ORB) from different layers of deep network.\n","\n","*   Load ResNet50 model with imagenet weights and check the summary of the model\n","*   Create a model to extract features from the 'avg_pool' layer.\n","*   Extract features from the layer for all the train images.\n","*   Use the extracted features to train a SVM classifier.\n","    *    Use GridSearchCV and SVC to perform the classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJ83bPO3mO16"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"n3CeHn372_J8"},"source":["*    Evaluate the trained SVM model using the test set\n","*    Calculate the accuracy score and confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRwVH6bc3Ob6"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0iNWSH-M1Lv1"},"source":["# Feature Visualizations\n","\n","In order to visualize the features of a higher dimension data, t-SNE is used. t-SNE converts the affinities of the data points to probabilities. It recreates the probability distribution in a low-dimensional space. It is very helpful in visualizing features of different layers in a neural network.\n","\n","You can find more information about t-SNE [here](https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne)"]},{"cell_type":"markdown","metadata":{"id":"U84jVNvR39CD"},"source":["*    Use TSNE to visualize the features extracted in the previous exercise.\n","    *    Hint: TSNE function is available in the *sklearn.manifold* package."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNTOB1gN4RC2"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pOYsp8jZ4Rce"},"source":["*    Why is feature visualization helpful?"]},{"cell_type":"markdown","metadata":{"id":"D5DlpPak4ZYG"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
