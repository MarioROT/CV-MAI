{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk0eYw8ojrFq"
      },
      "source": [
        "# Laboratory #3_2 : Image Classification using Bag of Visual Words\n",
        "\n",
        "At the end of this laboratory, you would get familiarized with\n",
        "\n",
        "*   Creating Bag of Visual Words\n",
        "    *   Feature Extraction\n",
        "    *   Codebook construction\n",
        "    *   Classification\n",
        "\n",
        "**Remember this is a graded exercise.**\n",
        "\n",
        "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
        "*   Create reusable functions where ever possible, so that the code could be reused at different places.\n",
        "*   Mount your drive to access the images.\n",
        "*   Add sufficient comments and explanations wherever necessary.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sYHw1lSBldl-",
        "outputId": "f99f3d31-2d80-4527-ea60-f13a126743c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CV-MAI'...\n",
            "remote: Enumerating objects: 21081, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 21081 (delta 3), reused 1 (delta 1), pack-reused 21072\u001b[K\n",
            "Receiving objects: 100% (21081/21081), 171.02 MiB | 26.83 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n",
            "Updating files: 100% (21037/21037), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "git clone https://github.com/mariorot/CV-MAI\n",
        "mv CV-MAI/scripts/* /content/\n",
        "mv 'CV-MAI/Session 7/101_ObjectCategories/'* /content/\n",
        "mv 'CV-MAI/Session 7/Caltech_101_subset/' /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "aD5-E8PuaQ5P"
      },
      "outputs": [],
      "source": [
        "# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from skimage.feature import ORB\n",
        "from skimage import feature\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread\n",
        "from scipy.cluster.vq import vq\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io\n",
        "from collections import defaultdict\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "import custom_plots as cp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ampx9DIJiuGN"
      },
      "source": [
        "## Loading dataset\n",
        "\n",
        "We will use 3 categories from Caltech 101 objects dataset for this experiment. Upload the dataset to the drive and mount it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "PRSJP1XbG6-a"
      },
      "outputs": [],
      "source": [
        "# modify the dataset variable with the path from your drive\n",
        "\n",
        "#We define an empty dictionary an the root folder of the 3 categories\n",
        "images_dict = defaultdict(list)\n",
        "root_folder = '/content/Caltech_101_subset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "fNoe7u755X6Q"
      },
      "outputs": [],
      "source": [
        "categories = ['butterfly', 'kangaroo', 'dalmatian']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxY0mDoK5EQj"
      },
      "source": [
        "*   Create a list of file and the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "EQptvDX5AFem"
      },
      "outputs": [],
      "source": [
        "# solution\n",
        "\n",
        "#We charged the images to the dictionary with the proper label and id\n",
        "for folder_name in os.listdir(root_folder):\n",
        "  folder_path = os.path.join(root_folder, folder_name)\n",
        "  if os.path.isdir(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "      if filename.endswith(('.jpg')):\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "        image_id= os.path.join(folder_name, filename)\n",
        "        image = io.imread(image_path)\n",
        "        label = folder_name\n",
        "        images_dict[image_id].append( (image,label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3x42veHz5LDt",
        "outputId": "b4cc68cc-164a-4be4-8ead-34ec5c690709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images: 244\n"
          ]
        }
      ],
      "source": [
        "print('Total number of images:', len(images_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgVhdjYz5Zhs"
      },
      "source": [
        "*   Create a train / test split where the test is 10% of the total data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "QzYnjzXBZXXt",
        "outputId": "ba4473c7-335a-4880-db26-9cf1501d849a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 219\n",
            "Test set: 25\n"
          ]
        }
      ],
      "source": [
        "# solution\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "keys = list(images_dict.keys())\n",
        "values = list(images_dict.values())\n",
        "\n",
        "train_keys, test_keys, train_values, test_values = train_test_split(keys, values, test_size=0.1, random_state=7)\n",
        "\n",
        "x_train = {k: v for k, v in zip(train_keys, train_values)}\n",
        "x_test = {k: v for k, v in zip(test_keys, test_values)}\n",
        "\n",
        "print('Train set:', len(x_train))\n",
        "print('Test set:', len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hl36Ej_5k6Y"
      },
      "source": [
        "*   How do you select the train/test split?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aOe27Kx5vtd"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "In this case, since the split of the classes was somehow homogeneous  (91 images of butterfly - 37% , 67 images of dalmatian - 28% and 86 images of kangaroos - 35%)  and the test data was only 10% of the total data set, we decided to do it in a random way.\n",
        "\n",
        "However, this may not be possible in 2 scenarios:\n",
        "\n",
        "- The distribution of the actual images was not homogeneous. For example having only 10% of an specific class. Because this way, there is a chance that we do not take enough images of the small class for the training set.\n",
        "\n",
        "- The total training set was small enough to contain only images of the same class.\n",
        "\n",
        "Since neither of these scenarios were happening we decided to do it randomly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18OZf2kfkVNB"
      },
      "source": [
        "## Feature Extraction using ORB\n",
        "\n",
        "The first step is to extract descriptors for each image in our dataset. We will use ORB to extract descriptors.\n",
        "\n",
        "*   Create ORB detector with 64 keypoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ptLbPcoow-ar"
      },
      "outputs": [],
      "source": [
        "# solution\n",
        "def get_ORB(img1,n):\n",
        "  descriptor_extractor = feature.ORB(n_keypoints=n)\n",
        "  descriptor_extractor.detect_and_extract(img1)\n",
        "  keypoints= descriptor_extractor.keypoints\n",
        "  descriptors= descriptor_extractor.descriptors\n",
        "\n",
        "  return descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yinPkL8brow"
      },
      "source": [
        "*   Extract ORB descriptors from all the images in the train set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "PCiXJeLFxGtP"
      },
      "outputs": [],
      "source": [
        "# solution\n",
        "f_desc=[]\n",
        "\n",
        "for image in x_train:\n",
        "  if len(x_train[image][0][0].shape)==3:\n",
        "    desc=get_ORB(rgb2gray(x_train[image][0][0]),64)\n",
        "    f_desc.append(desc)\n",
        "  else:\n",
        "    desc=get_ORB(x_train[image][0][0],64)\n",
        "    f_desc.append(desc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJehFdyt583b"
      },
      "source": [
        "*   What is the size of the feature descriptors? What does each dimension represent in the feature descriptors?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "bzTspvF96LeC",
        "outputId": "fc4f8635-a68b-47ca-cd22-64167b0c999b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# solution\n",
        "print(len(f_desc))\n",
        "f_desc[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNFOjsRj6PGk"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "The size of the feature descriptor is 64x256\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "420YQkAzleTQ"
      },
      "source": [
        "## Codebook Construction\n",
        "\n",
        "Codewords are nothing but vector representation of similar patches. This codeword produces a codebook similar to a word dictionary. We will create the codebook using K-Means algorithm\n",
        "\n",
        "*   Create a codebook using K-Means with k=number_of_classes*10\n",
        "*   Hint: Use sklearn.cluster.MiniBatchKMeans for K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "iO0e4718ppJt",
        "outputId": "44a6119a-8d6d-4afd-dafd-8eb81abc8301",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Codebook:\n",
            "[[0.30074349 0.70743494 0.38847584 ... 0.51784387 0.64200743 0.31895911]\n",
            " [0.55026455 0.88947678 0.4244562  ... 0.40446796 0.69135802 0.75661376]\n",
            " [0.46440307 0.77437021 0.32694414 ... 0.44852136 0.80613363 0.51971522]\n",
            " ...\n",
            " [0.38973384 0.46197719 0.51901141 ... 0.40494297 0.34648289 0.41397338]\n",
            " [0.6408787  0.43027698 0.38729704 ... 0.60840497 0.52292264 0.78510029]\n",
            " [0.48008611 0.16576964 0.47847147 ... 0.6926803  0.39181916 0.28040904]]\n"
          ]
        }
      ],
      "source": [
        "# solution\n",
        "patches = np.concatenate(f_desc, axis=0)\n",
        "k = len(categories) * 10\n",
        "kmeans = MiniBatchKMeans(n_clusters=k)\n",
        "kmeans.fit(patches)\n",
        "\n",
        "codebook = kmeans.cluster_centers_\n",
        "\n",
        "print(\"Codebook:\")\n",
        "print(codebook)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codebook.shape"
      ],
      "metadata": {
        "id": "hp3kcYz7rrzV",
        "outputId": "59a3a0d2-3585-4c36-a7ab-34e4f1c5835c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GAD_JuNpqMt"
      },
      "source": [
        "*   Create a histogram using the cluster centers for each image descriptor.\n",
        "    *   Remember the histogram would be of size *n_images x n_clusters*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR0_9HnbDFBe"
      },
      "outputs": [],
      "source": [
        "# solution\n",
        "\n",
        " im_features = np.array([np.zeros(no_clusters) for i in range(image_count)])\n",
        "    for i in range(image_count):\n",
        "        for j in range(len(descriptor_list[i])):\n",
        "            feature = descriptor_list[i][j]\n",
        "            feature = feature.reshape(1, 128)\n",
        "            idx = kmeans.predict(feature)\n",
        "            im_features[i][idx] += 1\n",
        "\n",
        "\n",
        "histograms = []\n",
        "for image_descriptor in patches:\n",
        "    # Assign each descriptor to a cluster\n",
        "    labels = kmeans.predict(image_descriptor)\n",
        "\n",
        "    # Build a histogram of size 215x30\n",
        "    histogram, _ = np.histogram(labels, bins=np.arange(k + 1))\n",
        "    histograms.append(histogram)\n",
        "\n",
        "# Convert the list of histograms into a 2D NumPy array\n",
        "histograms_array = np.array(histograms)\n",
        "\n",
        "# Display the histograms\n",
        "plt.imshow(histograms_array, aspect='auto', cmap='viridis')\n",
        "plt.xlabel('Cluster Index')\n",
        "plt.ylabel('Image Index')\n",
        "plt.title('Histograms of Cluster Assignments')\n",
        "plt.colorbar(label='Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmRO7dfLjgZa"
      },
      "source": [
        "\n",
        "# Creating Classification Model\n",
        "\n",
        "*   The next step is to create a classification model. We will use a C-Support Vector Classification for creating the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "K7VTBz1Oimtz"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrit95Ud6pUU"
      },
      "source": [
        "*   Use GridSearchCV to find the optimal value of C and Gamma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjFFpykV-GOI"
      },
      "outputs": [],
      "source": [
        "    Cs = [0.5, 0.1, 0.15, 0.2, 0.3]\n",
        "    gammas = [0.1, 0.11, 0.095, 0.105]\n",
        "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
        "    grid_search = GridSearchCV(SVC(kernel=kernel), param_grid, cv=5)\n",
        "    grid_search.fit(x_train[:][0][0],x_train[:][0][1] )\n",
        "    grid_search.best_params_\n",
        "    return grid_search.best_params_\n",
        "\n",
        "\n",
        "    svm = SVC(kernel = kernel, C =  C_param, gamma = gamma_param, class_weight = class_weight)\n",
        "    svm.fit(features, train_labels)\n",
        "    return svm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqThTmO5j1-p"
      },
      "source": [
        "# Testing the Classification Model\n",
        "\n",
        "*   Extract descriptors using ORB for the test split\n",
        "*   Use the previously trained k-means to generate the histogram\n",
        "*   Use the classifier to predict the label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2Gzbww9e0pP"
      },
      "outputs": [],
      "source": [
        "# solution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGyQUtU3lAEz"
      },
      "source": [
        "*   Calculate the accuracy score for the classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PszxSB0Ek_Lt"
      },
      "outputs": [],
      "source": [
        "# solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drlq-5AM615_"
      },
      "source": [
        "*   Generate the confusion matrix for the classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpqXVYrw61OG"
      },
      "outputs": [],
      "source": [
        "# solution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TN4rRra9yv_"
      },
      "source": [
        "*   Why do we use Clustering to create the codebook?\n",
        "*   What are the other techniques that can be used to create the codebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9kU3wa3Rei"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "- We use the clustering since we want to bring together all the descriptors that are similar in order to not get duplicates and just keep a limited amount of descriptors.\n",
        "\n",
        "- Since the main objective is to keep the similar information, most of the common clustering techniques will suit properly this task, as the hierarchical or agglomerative clustering. However we can use also some techniques as PCA that tries to achieve a dimmensionality reduction while keeping most of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b47OqebCOXpq"
      },
      "source": [
        "# Increased Feature Dimensions\n",
        "\n",
        "*   Repeat the classification using features of 256 ORB keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "CiY8GERXOxbB"
      },
      "outputs": [],
      "source": [
        "# solution\n",
        "\n",
        "f_desc_2=[]\n",
        "\n",
        "for image in x_train:\n",
        "  if len(x_train[image][0][0].shape)==3:\n",
        "    desc=get_ORB(rgb2gray(x_train[image][0][0]),256)\n",
        "    f_desc_2.append(desc)\n",
        "  else:\n",
        "    desc=get_ORB(x_train[image][0][0],256)\n",
        "    f_desc_2.append(desc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucf5mIeHOzBf"
      },
      "source": [
        "*   What is the difference in classifier performance between using 64 keypoints and 256 keypoints?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJt7kpHcO5nV"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "The accuracy increases since we are taking into account more details of the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll0j8G-oIaHd"
      },
      "source": [
        "*   Will further adding more keypoints increase the performance of the algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka3z1sJVInS5"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "No, since it happens with most algorithms more data may impply more precision, but there is a point reach where it does not give more information, and it only increases the computation time.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}